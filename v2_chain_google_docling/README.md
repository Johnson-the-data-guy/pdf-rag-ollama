RAG V2: Chain & Memory with Google Gemini + DoclingThis is the advanced version of the RAG system. Unlike V1 (which was manual and stateless), this version uses LangChain Chains, Conversation Memory, and FastAPI to create a true chatbot experience. It also replaces Tesseract OCR with Docling for superior document parsing.üöÄ Key Features & ChangesFeatureV1 (Manual/Flask)V2 (Chain/FastAPI)FrameworkFlask (Simple)FastAPI (Async, Type-Safe, Auto-Docs)ParsingTesseract OCR (Raw Text)Docling (Preserves Layout & Tables)ChunkingRecursive Character SplitHybrid Chunking (Semantic/Structure aware)LogicManual LoopsLangChain Chains (ConversationalRetrievalChain)MemoryNone (Stateless)Session Rehydration (Stateful Context)ModelsOllama (Local)Google Gemini (Cloud API)üß† Concepts Explained1. Docling & Hybrid ChunkingStandard chunkers blindly cut text every 1000 characters, often breaking sentences or tables in half.Docling parses the PDF into a rich JSON object that understands the document's physical layout (headers, bounding boxes, tables).Hybrid Chunking uses a local tokenizer (HuggingFace) to mathematically determine the best places to cut. It respects document boundaries, ensuring that a paragraph under a specific header stays connected to that header.2. Chains (The "Autopilot")In V1, we manually coded: Embed -> Search -> Prompt -> Generate.In V2, we use ConversationalRetrievalChain. This pre-built logic handles the complex flow automatically:It looks at your chat history.It rewrites your question (e.g., "How much is it?" $\rightarrow$ "How much is the iPhone?").It retrieves documents based on the rewritten question.It generates the answer.3. Memory & RehydrationAPIs are "stateless" (they forget you immediately). To enable chat history:The Frontend sends the entire conversation history with every new message.The FastAPI backend "Rehydrates" a temporary memory object with this history before processing the new question.This gives the illusion of a persistent conversation without needing a server-side database session.üõ†Ô∏è Setup & Usage1. Install DependenciesEnsure you are in the v2_chain_google_docling directory.# Activate venv first
pip install -r requirements.txt 2. Environment VariablesCreate a .env file in the project root:GOOGLE_API_KEY="your_gemini_api_key" 3. Run the APIThis starts the server on Port 8000.# Run using Python directly
python app_chain.py

# OR using Uvicorn

uvicorn app_chain:app --port 8000 --reload 4. Interactive DocsOnce running, visit http://localhost:8000/docs to test the API without the frontend.
